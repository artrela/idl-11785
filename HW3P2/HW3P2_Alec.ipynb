{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA9qZoIDcx-h",
        "outputId": "993041c5-72fb-4ef2-8c88-ccd0157e1f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONgAWhqdoYy-"
      },
      "source": [
        "\n",
        "This may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7a7xeEoaV9",
        "outputId": "a2936aba-9593-4481-af6e-9a4be2131c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.9/264.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 782.27 KiB | 8.41 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Counting objects: 100% (26/26), done.        \n",
            "remote: Compressing objects: 100% (9/9), done.        \n",
            "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56        \n",
            "Receiving objects: 100% (82/82), 13.34 KiB | 2.67 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14165, done.        \n",
            "remote: Counting objects: 100% (478/478), done.        \n",
            "remote: Compressing objects: 100% (332/332), done.        \n",
            "remote: Total 14165 (delta 163), reused 409 (delta 132), pack-reused 13687        \n",
            "Receiving objects: 100% (14165/14165), 5.91 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (8043/8043), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/ctcdecode\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb --quiet\n",
        "!pip install python-Levenshtein -q\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget -q\n",
        "%cd ctcdecode\n",
        "!pip install . -q\n",
        "%cd ..\n",
        "\n",
        "!pip install torchsummaryX==1.3.0 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "HKLIou7YPo2Q",
        "outputId": "d7e4960a-d98a-4baa-a25e-d08c6e5562cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nIf torchsummaryX doesn't work, please run this cell. Alternatively, please refer to Piazza post @209 for more assistance:\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "If torchsummaryX doesn't work, please run this cell. Alternatively, please refer to Piazza post @209 for more assistance:\n",
        "'''\n",
        "\n",
        "# !pip install torchsummaryx====1.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVONJxCobPc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78ZTCIXoof2f",
        "outputId": "0cc9fc0e-44ae-4dcd-aea2-d36ee53fbec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import glob\n",
        "import pdb\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-6_3rjbUzGv"
      },
      "source": [
        "# Handout Notes:\n",
        "\n",
        "- This problem is hard because it is order-aligned but not time-synchronous\n",
        "  - It is not immediately obvious where the sequence \"Y\\EH\\S\" would align to each cell of a recurrent network\n",
        "- CTC is used for this reason. Instead of relying on the network to produce outputs at erratic times, you have the network produce outputs at every time and then perform a DP solution to search over the output space.\n",
        "- Model Notes:\n",
        "  - Generally:\n",
        "    - Use GRU/LSTM\n",
        "    - Model can be bidirectional since we have the whole input sequence at test time\n",
        "    - Downsampling the input sequence could be advantageous and is realistic since an audio file will often repeat phenomes over multiple time steps\n",
        "  - Specifically:\n",
        "    - 1D CNN can extract latent features\n",
        "    - try bi-LSTMs or pBiLSTMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGloIcuOb6_1"
      },
      "source": [
        "# TODOs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3-yJ8tok34"
      },
      "source": [
        "# Kaggle Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdUelfGhom1m",
        "outputId": "0d4202e2-b125-45c2-f73b-b4e89e1e0ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8 -q\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"alectrela\",\"key\":\"42d0f6df23d52bb3b9e5a7b2cb5e1962\"}') # TODO: Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSjBwfXeoq4B",
        "outputId": "cfb353fc-2984-4308-996e-4201e9ac7a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hw3p2asr-s24.zip to /content\n",
            "100% 3.74G/3.74G [01:38<00:00, 36.4MB/s]\n",
            "100% 3.74G/3.74G [01:38<00:00, 40.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c hw3p2asr-s24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ruxWP60LCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ef5572-99f5-4af2-9a16-23db011f0d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11-785-s24-hw3p2  ctcdecode  hw3p2asr-s24.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This will take a couple minutes, but you should see at least the following:\n",
        "11-785-s24-hw3p2  ctcdecode  hw3p2asr-s24.zip  sample_data\n",
        "'''\n",
        "!unzip -q hw3p2asr-s24.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9v5ewZDMpYA"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8WCmO6EHhN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41fe164-2037-4a93-a948-ffbaddaba495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ORNHnSFroP0"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "outputs": [],
      "source": [
        "# ARPABET PHONEME MAPPING\n",
        "# DO NOT CHANGE\n",
        "\n",
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict[:-2]\n",
        "LABELS = ARPAbet[:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "outputs": [],
      "source": [
        "root = '/content/11-785-s24-hw3p2/'\n",
        "\n",
        "# Feel free to add more items here\n",
        "config = {\n",
        "    \"model\"      : \"transforms-1\",\n",
        "    \"beam_width\" : 10,\n",
        "    \"lr\"         : 1.5e-3,\n",
        "    \"epochs\"     : 50,\n",
        "    \"batch_size\" : 128,  # Increase if your device can handle it\n",
        "    \"milestones\": [15, 20, 25, 30, 35, 40, 45],\n",
        "    \"gamma\"      : 0.4,\n",
        "    \"freq_mask\" : random.randint(35, 65),\n",
        "    \"time_mask\" : random.randint(90, 150),\n",
        "    \"time_p\": (random.random() * 0.35) + 0.25,\n",
        "    \"embed_size\": 220\n",
        "}\n",
        "\n",
        "# You may pass this as a parameter to the dataset class above\n",
        "# This will help modularize your implementation\n",
        "transforms = [\n",
        "    tat.FrequencyMasking(freq_mask_param=config[\"freq_mask\"]),\n",
        "    tat.TimeMasking(time_mask_param=config[\"time_mask\"], p=config[\"time_p\"])\n",
        " ] # set of tranformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN2kcxwXLLBb"
      },
      "outputs": [],
      "source": [
        "# You might want to play around with the mapping as a sanity check here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmNBKf4JrLV"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "    #TODO\n",
        "    def __init__(self, root, phonemes=PHONEMES, partition=\"train-clean-100\", transforms=None):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.transforms = torch.nn.Sequential(*transforms) if transforms is not None else None\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = os.path.join(root + \"/\" + partition + \"/mfcc/\")\n",
        "        self.transcript_dir = os.path.join(root + \"/\" + partition + \"/transcript/\")\n",
        "\n",
        "        self.mfcc_files = [os.path.join(self.mfcc_dir + file) for file in sorted(os.listdir(self.mfcc_dir))]\n",
        "        self.transcript_files = [os.path.join(self.transcript_dir + file) for file in sorted(os.listdir(self.transcript_dir))]\n",
        "\n",
        "        self.phonemes = phonemes\n",
        "\n",
        "        #TODO\n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        assert len(self.mfcc_files) == len(self.transcript_files)\n",
        "        self.length = len(self.mfcc_files)\n",
        "\n",
        "        #TODO\n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "\n",
        "\n",
        "        #TODO\n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "        self.mfccs = []\n",
        "        self.transcripts = []\n",
        "\n",
        "        for i in tqdm(range(len(self.mfcc_files)), desc=f\"Creating {partition}\"):\n",
        "            mfcc_file = self.mfcc_files[i]\n",
        "            transcript_file = self.transcript_files[i]\n",
        "\n",
        "            mfcc = np.load(mfcc_file)\n",
        "            # normalize\n",
        "            mfcc = (mfcc - mfcc.mean(axis=0, keepdims=True)) / (mfcc.std(axis=0, keepdims=True) + 1e-5)\n",
        "\n",
        "            transcript  = np.load(transcript_file)[1:-1]\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "\n",
        "        for i in range(len(self.transcripts)):\n",
        "          self.transcripts[i] = [phonemes.index(phoneme) for phoneme in self.transcripts[i]]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "        mfcc = torch.FloatTensor(self.mfccs[ind]) # TODO\n",
        "        transcript = torch.tensor(self.transcripts[ind]) # TODO\n",
        "\n",
        "        return mfcc, transcript\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lengths of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "\n",
        "        #######################################################################\n",
        "        \"\"\"\n",
        "        NOTE: What is the collate_fn? https://www.youtube.com/watch?v=5hH3CVzy8zs\n",
        "\n",
        "        The collate_fn parameter in a PyTorch DataLoader allows you to control how\n",
        "        individual data samples are combined into a batch. By default, the DataLoader\n",
        "        stacks the data samples along the first dimension to form a batch. However,\n",
        "        not all data can be neatly stacked this way (think about images of different\n",
        "        sizes or text sequences of varying lengths). Here's where collate_fn shines—it's\n",
        "        your Swiss Army knife for handling these quirks elegantly.\n",
        "\n",
        "        https://plainenglish.io/blog/understanding-collate-fn-in-pytorch-f9d1742647d3\n",
        "        collate essentially allows you to\n",
        "\n",
        "        \"\"\"\n",
        "        #######################################################################\n",
        "\n",
        "        # batch of input mfcc coefficients\n",
        "         # TODO\n",
        "        # batch of output phonemes\n",
        "         # TODO\n",
        "        batch_mfcc = [] # TODO\n",
        "        batch_transcript = [] # TODO\n",
        "        for mfcc, transcript in batch:\n",
        "            batch_mfcc.append(mfcc)\n",
        "            batch_transcript.append(transcript)\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_mfcc_pad = torch.nn.utils.rnn.pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        lengths_mfcc = [len(mfcc) for mfcc in batch_mfcc] # TODO\n",
        "\n",
        "        batch_transcript_pad = torch.nn.utils.rnn.pad_sequence(batch_transcript, batch_first=True) # TODO\n",
        "        lengths_transcript = [len(transcript) for transcript in batch_transcript] # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            batch_mfcc_pad = self.transforms(batch_mfcc_pad)\n",
        "            # batch_transcript_pad = self.transform(batch_transcript_pad)\n",
        "\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDrxeHfJw4g"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrLS1wfVJppA"
      },
      "outputs": [],
      "source": [
        "class AudioDatasetTest(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "    #TODO\n",
        "    def __init__(self, root, phonemes=PHONEMES, partition=\"test-clean\"):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = os.path.join(root + \"/\" + partition + \"/mfcc/\")\n",
        "\n",
        "        self.mfcc_files = [os.path.join(self.mfcc_dir + file) for file in sorted(os.listdir(self.mfcc_dir))]\n",
        "\n",
        "        self.phonemes = phonemes\n",
        "\n",
        "        #TODO\n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfcc_files)\n",
        "\n",
        "        #TODO\n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "\n",
        "\n",
        "        #TODO\n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "        self.mfccs = []\n",
        "\n",
        "        for i in tqdm(range(len(self.mfcc_files)), desc=f\"Creating {partition}\"):\n",
        "            mfcc_file = self.mfcc_files[i]\n",
        "\n",
        "            mfcc = np.load(mfcc_file)\n",
        "            # normalize\n",
        "            mfcc = (mfcc - mfcc.mean(axis=0, keepdims=True)) / (mfcc.std(axis=0, keepdims=True) + 1e-5)\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "        mfcc = torch.FloatTensor(self.mfccs[ind]) # TODO\n",
        "\n",
        "        return mfcc\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lengths of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "\n",
        "        #######################################################################\n",
        "        \"\"\"\n",
        "        NOTE: What is the collate_fn? https://www.youtube.com/watch?v=5hH3CVzy8zs\n",
        "\n",
        "        The collate_fn parameter in a PyTorch DataLoader allows you to control how\n",
        "        individual data samples are combined into a batch. By default, the DataLoader\n",
        "        stacks the data samples along the first dimension to form a batch. However,\n",
        "        not all data can be neatly stacked this way (think about images of different\n",
        "        sizes or text sequences of varying lengths). Here's where collate_fn shines—it's\n",
        "        your Swiss Army knife for handling these quirks elegantly.\n",
        "\n",
        "        https://plainenglish.io/blog/understanding-collate-fn-in-pytorch-f9d1742647d3\n",
        "        collate essentially allows you to\n",
        "\n",
        "        \"\"\"\n",
        "        #######################################################################\n",
        "\n",
        "        # batch of input mfcc coefficients\n",
        "         # TODO\n",
        "        # batch of output phonemes\n",
        "         # TODO\n",
        "        batch_mfcc = [] # TODO\n",
        "        for mfcc in batch:\n",
        "            batch_mfcc.append(mfcc)\n",
        "\n",
        "        batch_mfcc_pad = torch.nn.utils.rnn.pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        lengths_mfcc = [len(mfcc) for mfcc in batch_mfcc] # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-veYcdL6Fe"
      },
      "source": [
        "### Config - Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmuPk9J6L8dz"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_kG0gU2x4hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d83971-3a49-410b-fc3c-f12f116ac99f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1191"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# get me RAMMM!!!!\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mzoYfTKu14s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399b6401-ed1a-41b6-beb7-27661339988b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating train-clean-100: 100%|██████████| 28539/28539 [00:18<00:00, 1552.50it/s]\n",
            "Creating dev-clean: 100%|██████████| 2703/2703 [00:01<00:00, 1846.30it/s]\n",
            "Creating test-clean: 100%|██████████| 2620/2620 [00:01<00:00, 2548.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  128\n",
            "Train dataset samples = 28539, batches = 223\n",
            "Val dataset samples = 2703, batches = 22\n",
            "Test dataset samples = 2620, batches = 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create objects for the dataset class\n",
        "train_data = AudioDataset(root, transforms=transforms)\n",
        "val_data = AudioDataset(root, partition=\"dev-clean\")\n",
        "test_data = AudioDatasetTest(root)\n",
        "\n",
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn  = train_data.collate_fn\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False,\n",
        "    collate_fn  = val_data.collate_fn\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False,\n",
        "    collate_fn  = test_data.collate_fn\n",
        ")\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXMtwyviKaxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4277cba4-9ceb-48c0-d463-e6113c90be9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1662, 27]) torch.Size([128, 191]) torch.Size([128]) torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSexxhdfMUzx"
      },
      "source": [
        "# NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLad4pChcuvX"
      },
      "source": [
        "## Basic\n",
        "\n",
        "This is a basic block for understanding, you can skip this and move to pBLSTM one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQhvHr71GJfq"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# class Network(nn.Module):\n",
        "\n",
        "#     def __init__(self, out_feats=41):\n",
        "\n",
        "#         super(Network, self).__init__()\n",
        "\n",
        "#         # Adding some sort of embedding layer or feature extractor might help performance.\n",
        "#         # self.embedding = ?\n",
        "\n",
        "#         # TODO : look up the documentation. You might need to pass some additional parameters.\n",
        "#         self.lstm = nn.LSTM(input_size = __, hidden_size = 256, num_layers = 1)\n",
        "\n",
        "#         self.classification = nn.Sequential(\n",
        "#             #TODO: Linear layer with in_features from the lstm module above and out_features = OUT_SIZE\n",
        "#         )\n",
        "\n",
        "\n",
        "#         self.logSoftmax = #TODO: Apply a log softmax here. Which dimension would apply it on ?\n",
        "\n",
        "#     def forward(self, x, lx):\n",
        "#         #TODO\n",
        "#         # The forward function takes 2 parameter inputs here. Why?\n",
        "#         # Refer to the handout for hints\n",
        "#         pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUThsowyQdN7"
      },
      "source": [
        "## Initialize Basic Network\n",
        "(If trying out the basic Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGoiXd70tb5z"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# model = Network().to(device)\n",
        "# summary(model, x.to(device), lx) # x and lx come from the sanity check above :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-qb7wnAzCZl"
      },
      "source": [
        "## ASR Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6eh3gnMUzy"
      },
      "source": [
        "### Pyramid Bi-LSTM (pBLSTM)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del model\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YJBMHcrGM3XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd4BEX_yMUzz"
      },
      "outputs": [],
      "source": [
        "# Utils for network\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmdyXI6KMUzz"
      },
      "outputs": [],
      "source": [
        "class pBLSTM(torch.nn.Module):\n",
        "\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
        "\n",
        "    At each step,\n",
        "    1. Pad your input if it is packed (Unpack it)\n",
        "    2. Reduce the input length dimension by concatenating feature dimension\n",
        "        (Tip: Write down the shapes and understand)\n",
        "        (i) How should  you deal with odd/even length input?\n",
        "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
        "    3. Pack your input\n",
        "    4. Pass it into LSTM layer\n",
        "\n",
        "    To make our implementation modular, we pass 1 layer at a time.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, layers=1, dropout=0.0):\n",
        "        super(pBLSTM, self).__init__()\n",
        "\n",
        "        self.blstm = torch.nn.LSTM(input_size, hidden_size,\n",
        "                                   batch_first=True, bidirectional=True,\n",
        "                                   dropout=dropout, num_layers=layers)\n",
        "        # TODO: Initialize a single layer bidirectional LSTM with the given input_size and hidden_size\n",
        "\n",
        "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
        "\n",
        "        # TODO: Pad Packed Sequence\n",
        "\n",
        "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
        "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
        "        # TODO: Pack Padded Sequence. What output(s) would you get?\n",
        "        # TODO: Pass the sequence through bLSTM\n",
        "\n",
        "        x, x_lens = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)\n",
        "\n",
        "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
        "        x, x_lens = self.trunc_reshape(x, x_lens)\n",
        "\n",
        "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
        "        # Pack Padded Sequence. What output(s) would you get?\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "\n",
        "        out, _ = self.blstm(x_packed)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def trunc_reshape(self, x, x_lens):\n",
        "        # TODO: If you have odd number of timesteps, how can you handle it? (Hint: You can exclude them)\n",
        "        # TODO: Reshape x. When reshaping x, you have to reduce number of timesteps by a downsampling factor while increasing number of features by the same factor\n",
        "        # TODO: Reduce lengths by the same downsampling factor\n",
        "\n",
        "        B, L, D = x.shape\n",
        "\n",
        "        # get rid of 1 if length is odd\n",
        "        if L % 2 != 0:\n",
        "          x = x[:, :-1, :]\n",
        "\n",
        "        # per pyramidal, reduce length to increase computation speed\n",
        "        x = x.reshape(B, L // 2, D*2)\n",
        "        x_lens = x_lens // 2\n",
        "\n",
        "\n",
        "        return x, x_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3ZQ75OcMUz0"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEzw5_xmMUz0"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        '''\n",
        "        the purpose of this is to increase the dimensionality to express\n",
        "        27 channels more effectively.\n",
        "\n",
        "        you can also increase stride here to downsample the input to increase comp speed.\n",
        "        Dont do too much or else you will rid important information from the input.\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            PermuteBlock(),\n",
        "            torch.nn.Conv1d(input_size, encoder_hidden_size//3, kernel_size=5, padding=5//2),\n",
        "            torch.nn.BatchNorm1d(encoder_hidden_size//3),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout1d(0.1),\n",
        "            torch.nn.Conv1d(encoder_hidden_size//3, encoder_hidden_size//2, kernel_size=3, padding=3//2),\n",
        "            torch.nn.BatchNorm1d(encoder_hidden_size//2),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout1d(0.2),\n",
        "            torch.nn.Conv1d(encoder_hidden_size//2, encoder_hidden_size, kernel_size=3, padding=3//2),\n",
        "            torch.nn.BatchNorm1d(encoder_hidden_size),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout1d(0.1),\n",
        "            torch.nn.Conv1d(encoder_hidden_size, encoder_hidden_size, kernel_size=2, padding=2//2),\n",
        "            torch.nn.BatchNorm1d(encoder_hidden_size),\n",
        "            torch.nn.GELU(),\n",
        "            PermuteBlock(),\n",
        "        )\n",
        "\n",
        "         #TODO: You can use CNNs as Embedding layer to extract features. Keep in mind the Input dimensions and expected dimension of Pytorch CNN.\n",
        "\n",
        "        self.pBLSTMs = torch.nn.Sequential( # How many pBLSTMs are required?\n",
        "            # TODO: Fill this up with pBLSTMs - What should the input_size be?\n",
        "            # Hint: You are downsampling timesteps by a factor of 2, upsampling features by a factor of 2 and the LSTM is bidirectional)\n",
        "            # Optional: Dropout/Locked Dropout after each pBLSTM (Not needed for early submission)\n",
        "            # https://github.com/salesforce/awd-lstm-lm/blob/dfd3cb0235d2caf2847a4d53e1cbd495b781b5d2/locked_dropout.py#L5\n",
        "            # ...\n",
        "            # ...\n",
        "            pBLSTM(encoder_hidden_size*2, encoder_hidden_size, layers=2, dropout=0.15),\n",
        "            pBLSTM(encoder_hidden_size*4, encoder_hidden_size, layers=3, dropout=0.20),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        # TODO: Pack Padded Sequence\n",
        "        # TODO: Pass Sequence through the pyramidal Bi-LSTM layer\n",
        "        # TODO: Pad Packed Sequence\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "        out = self.pBLSTMs(x_packed)\n",
        "        encoder_outputs, encoder_lens = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
        "        # Remember the number of output(s) each function returns\n",
        "\n",
        "        return encoder_outputs, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg82HXa3MUz1"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQIRxdNTMUz1"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, output_size= 41):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            #TODO define your MLP arch. Refer HW1P2\n",
        "            #Use Permute Block before and after BatchNorm1d() to match the size\n",
        "            # PermuteBlock(),\n",
        "            # torch.nn.BatchNorm1d(embed_size),\n",
        "            # PermuteBlock(),\n",
        "            torch.nn.Linear(embed_size, embed_size),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.BatchNorm1d(embed_size),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(0.15),\n",
        "            torch.nn.Linear(embed_size, embed_size//2),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.BatchNorm1d(embed_size//2),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(0.15),\n",
        "            torch.nn.Linear(embed_size//2, embed_size//2),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.BatchNorm1d(embed_size//2),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(embed_size//2, output_size)\n",
        "        )\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out):\n",
        "        #TODO call your MLP\n",
        "        #TODO Think what should be the final output of the decoder for the classification\n",
        "\n",
        "        out = self.mlp(encoder_out)\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmHf6pFiMUz1"
      },
      "outputs": [],
      "source": [
        "class ASRModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embed_size= 192, output_size= len(PHONEMES)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.augmentations  = torch.nn.Sequential(\n",
        "            #TODO Add Time Masking/ Frequency Masking\n",
        "            #Hint: See how to use PermuteBlock() function defined above\n",
        "        )\n",
        "        self.encoder        = Encoder(input_size, embed_size)# TODO: Initialize Encoder\n",
        "        self.decoder        = Decoder(embed_size*2, output_size) # TODO: Initialize Decoder\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths_x):\n",
        "\n",
        "        # if self.training:\n",
        "        #     x = self.augmentations(x)\n",
        "\n",
        "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
        "        decoder_out                 = self.decoder(encoder_out)\n",
        "\n",
        "        return decoder_out, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV7DMPDoMUz2"
      },
      "source": [
        "## Initialize ASR Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaaDsnnLMUz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e35a9101-e359-440d-9d08-b22429a01651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASRModel(\n",
            "  (augmentations): Sequential()\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): Conv1d(27, 73, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "      (2): BatchNorm1d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): GELU(approximate='none')\n",
            "      (4): Dropout1d(p=0.1, inplace=False)\n",
            "      (5): Conv1d(73, 110, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (6): BatchNorm1d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (7): GELU(approximate='none')\n",
            "      (8): Dropout1d(p=0.2, inplace=False)\n",
            "      (9): Conv1d(110, 220, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (10): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (11): GELU(approximate='none')\n",
            "      (12): Dropout1d(p=0.1, inplace=False)\n",
            "      (13): Conv1d(220, 220, kernel_size=(2,), stride=(1,), padding=(1,))\n",
            "      (14): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (15): GELU(approximate='none')\n",
            "      (16): PermuteBlock()\n",
            "    )\n",
            "    (pBLSTMs): Sequential(\n",
            "      (0): pBLSTM(\n",
            "        (blstm): LSTM(440, 220, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
            "      )\n",
            "      (1): pBLSTM(\n",
            "        (blstm): LSTM(880, 220, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (mlp): Sequential(\n",
            "      (0): Linear(in_features=440, out_features=440, bias=True)\n",
            "      (1): PermuteBlock()\n",
            "      (2): BatchNorm1d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): PermuteBlock()\n",
            "      (4): GELU(approximate='none')\n",
            "      (5): Dropout(p=0.15, inplace=False)\n",
            "      (6): Linear(in_features=440, out_features=220, bias=True)\n",
            "      (7): PermuteBlock()\n",
            "      (8): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (9): PermuteBlock()\n",
            "      (10): GELU(approximate='none')\n",
            "      (11): Dropout(p=0.15, inplace=False)\n",
            "      (12): Linear(in_features=220, out_features=220, bias=True)\n",
            "      (13): PermuteBlock()\n",
            "      (14): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (15): PermuteBlock()\n",
            "      (16): GELU(approximate='none')\n",
            "      (17): Linear(in_features=220, out_features=41, bias=True)\n",
            "    )\n",
            "    (softmax): LogSoftmax(dim=2)\n",
            "  )\n",
            ")\n",
            "=============================================================================================\n",
            "                                       Kernel Shape      Output Shape  \\\n",
            "Layer                                                                   \n",
            "0_encoder.embedding.PermuteBlock_0                -   [128, 27, 1662]   \n",
            "1_encoder.embedding.Conv1d_1            [27, 73, 5]   [128, 73, 1662]   \n",
            "2_encoder.embedding.BatchNorm1d_2              [73]   [128, 73, 1662]   \n",
            "3_encoder.embedding.GELU_3                        -   [128, 73, 1662]   \n",
            "4_encoder.embedding.Dropout1d_4                   -   [128, 73, 1662]   \n",
            "5_encoder.embedding.Conv1d_5           [73, 110, 3]  [128, 110, 1662]   \n",
            "6_encoder.embedding.BatchNorm1d_6             [110]  [128, 110, 1662]   \n",
            "7_encoder.embedding.GELU_7                        -  [128, 110, 1662]   \n",
            "8_encoder.embedding.Dropout1d_8                   -  [128, 110, 1662]   \n",
            "9_encoder.embedding.Conv1d_9          [110, 220, 3]  [128, 220, 1662]   \n",
            "10_encoder.embedding.BatchNorm1d_10           [220]  [128, 220, 1662]   \n",
            "11_encoder.embedding.GELU_11                      -  [128, 220, 1662]   \n",
            "12_encoder.embedding.Dropout1d_12                 -  [128, 220, 1662]   \n",
            "13_encoder.embedding.Conv1d_13        [220, 220, 2]  [128, 220, 1663]   \n",
            "14_encoder.embedding.BatchNorm1d_14           [220]  [128, 220, 1663]   \n",
            "15_encoder.embedding.GELU_15                      -  [128, 220, 1663]   \n",
            "16_encoder.embedding.PermuteBlock_16              -  [128, 1663, 220]   \n",
            "17_encoder.pBLSTMs.0.LSTM_blstm                   -      [80412, 440]   \n",
            "18_encoder.pBLSTMs.1.LSTM_blstm                   -      [40177, 440]   \n",
            "19_decoder.mlp.Linear_0                  [440, 440]   [128, 415, 440]   \n",
            "20_decoder.mlp.PermuteBlock_1                     -   [128, 440, 415]   \n",
            "21_decoder.mlp.BatchNorm1d_2                  [440]   [128, 440, 415]   \n",
            "22_decoder.mlp.PermuteBlock_3                     -   [128, 415, 440]   \n",
            "23_decoder.mlp.GELU_4                             -   [128, 415, 440]   \n",
            "24_decoder.mlp.Dropout_5                          -   [128, 415, 440]   \n",
            "25_decoder.mlp.Linear_6                  [440, 220]   [128, 415, 220]   \n",
            "26_decoder.mlp.PermuteBlock_7                     -   [128, 220, 415]   \n",
            "27_decoder.mlp.BatchNorm1d_8                  [220]   [128, 220, 415]   \n",
            "28_decoder.mlp.PermuteBlock_9                     -   [128, 415, 220]   \n",
            "29_decoder.mlp.GELU_10                            -   [128, 415, 220]   \n",
            "30_decoder.mlp.Dropout_11                         -   [128, 415, 220]   \n",
            "31_decoder.mlp.Linear_12                 [220, 220]   [128, 415, 220]   \n",
            "32_decoder.mlp.PermuteBlock_13                    -   [128, 220, 415]   \n",
            "33_decoder.mlp.BatchNorm1d_14                 [220]   [128, 220, 415]   \n",
            "34_decoder.mlp.PermuteBlock_15                    -   [128, 415, 220]   \n",
            "35_decoder.mlp.GELU_16                            -   [128, 415, 220]   \n",
            "36_decoder.mlp.Linear_17                  [220, 41]    [128, 415, 41]   \n",
            "37_decoder.LogSoftmax_softmax                     -    [128, 415, 41]   \n",
            "\n",
            "                                        Params  Mult-Adds  \n",
            "Layer                                                      \n",
            "0_encoder.embedding.PermuteBlock_0           -          -  \n",
            "1_encoder.embedding.Conv1d_1            9.928k  16.37901M  \n",
            "2_encoder.embedding.BatchNorm1d_2        146.0       73.0  \n",
            "3_encoder.embedding.GELU_3                   -          -  \n",
            "4_encoder.embedding.Dropout1d_4              -          -  \n",
            "5_encoder.embedding.Conv1d_5             24.2k  40.03758M  \n",
            "6_encoder.embedding.BatchNorm1d_6        220.0      110.0  \n",
            "7_encoder.embedding.GELU_7                   -          -  \n",
            "8_encoder.embedding.Dropout1d_8              -          -  \n",
            "9_encoder.embedding.Conv1d_9            72.82k  120.6612M  \n",
            "10_encoder.embedding.BatchNorm1d_10      440.0      220.0  \n",
            "11_encoder.embedding.GELU_11                 -          -  \n",
            "12_encoder.embedding.Dropout1d_12            -          -  \n",
            "13_encoder.embedding.Conv1d_13          97.02k  160.9784M  \n",
            "14_encoder.embedding.BatchNorm1d_14      440.0      220.0  \n",
            "15_encoder.embedding.GELU_15                 -          -  \n",
            "16_encoder.embedding.PermuteBlock_16         -          -  \n",
            "17_encoder.pBLSTMs.0.LSTM_blstm       2.33024M    2.3232M  \n",
            "18_encoder.pBLSTMs.1.LSTM_blstm       4.26976M    4.2592M  \n",
            "19_decoder.mlp.Linear_0                194.04k     193.6k  \n",
            "20_decoder.mlp.PermuteBlock_1                -          -  \n",
            "21_decoder.mlp.BatchNorm1d_2             880.0      440.0  \n",
            "22_decoder.mlp.PermuteBlock_3                -          -  \n",
            "23_decoder.mlp.GELU_4                        -          -  \n",
            "24_decoder.mlp.Dropout_5                     -          -  \n",
            "25_decoder.mlp.Linear_6                 97.02k      96.8k  \n",
            "26_decoder.mlp.PermuteBlock_7                -          -  \n",
            "27_decoder.mlp.BatchNorm1d_8             440.0      220.0  \n",
            "28_decoder.mlp.PermuteBlock_9                -          -  \n",
            "29_decoder.mlp.GELU_10                       -          -  \n",
            "30_decoder.mlp.Dropout_11                    -          -  \n",
            "31_decoder.mlp.Linear_12                48.62k      48.4k  \n",
            "32_decoder.mlp.PermuteBlock_13               -          -  \n",
            "33_decoder.mlp.BatchNorm1d_14            440.0      220.0  \n",
            "34_decoder.mlp.PermuteBlock_15               -          -  \n",
            "35_decoder.mlp.GELU_16                       -          -  \n",
            "36_decoder.mlp.Linear_17                9.061k      9.02k  \n",
            "37_decoder.LogSoftmax_softmax                -          -  \n",
            "---------------------------------------------------------------------------------------------\n",
            "                           Totals\n",
            "Total params            7.155715M\n",
            "Trainable params        7.155715M\n",
            "Non-trainable params          0.0\n",
            "Mult-Adds             344.987913M\n",
            "=============================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       Kernel Shape      Output Shape  \\\n",
              "Layer                                                                   \n",
              "0_encoder.embedding.PermuteBlock_0                -   [128, 27, 1662]   \n",
              "1_encoder.embedding.Conv1d_1            [27, 73, 5]   [128, 73, 1662]   \n",
              "2_encoder.embedding.BatchNorm1d_2              [73]   [128, 73, 1662]   \n",
              "3_encoder.embedding.GELU_3                        -   [128, 73, 1662]   \n",
              "4_encoder.embedding.Dropout1d_4                   -   [128, 73, 1662]   \n",
              "5_encoder.embedding.Conv1d_5           [73, 110, 3]  [128, 110, 1662]   \n",
              "6_encoder.embedding.BatchNorm1d_6             [110]  [128, 110, 1662]   \n",
              "7_encoder.embedding.GELU_7                        -  [128, 110, 1662]   \n",
              "8_encoder.embedding.Dropout1d_8                   -  [128, 110, 1662]   \n",
              "9_encoder.embedding.Conv1d_9          [110, 220, 3]  [128, 220, 1662]   \n",
              "10_encoder.embedding.BatchNorm1d_10           [220]  [128, 220, 1662]   \n",
              "11_encoder.embedding.GELU_11                      -  [128, 220, 1662]   \n",
              "12_encoder.embedding.Dropout1d_12                 -  [128, 220, 1662]   \n",
              "13_encoder.embedding.Conv1d_13        [220, 220, 2]  [128, 220, 1663]   \n",
              "14_encoder.embedding.BatchNorm1d_14           [220]  [128, 220, 1663]   \n",
              "15_encoder.embedding.GELU_15                      -  [128, 220, 1663]   \n",
              "16_encoder.embedding.PermuteBlock_16              -  [128, 1663, 220]   \n",
              "17_encoder.pBLSTMs.0.LSTM_blstm                   -      [80412, 440]   \n",
              "18_encoder.pBLSTMs.1.LSTM_blstm                   -      [40177, 440]   \n",
              "19_decoder.mlp.Linear_0                  [440, 440]   [128, 415, 440]   \n",
              "20_decoder.mlp.PermuteBlock_1                     -   [128, 440, 415]   \n",
              "21_decoder.mlp.BatchNorm1d_2                  [440]   [128, 440, 415]   \n",
              "22_decoder.mlp.PermuteBlock_3                     -   [128, 415, 440]   \n",
              "23_decoder.mlp.GELU_4                             -   [128, 415, 440]   \n",
              "24_decoder.mlp.Dropout_5                          -   [128, 415, 440]   \n",
              "25_decoder.mlp.Linear_6                  [440, 220]   [128, 415, 220]   \n",
              "26_decoder.mlp.PermuteBlock_7                     -   [128, 220, 415]   \n",
              "27_decoder.mlp.BatchNorm1d_8                  [220]   [128, 220, 415]   \n",
              "28_decoder.mlp.PermuteBlock_9                     -   [128, 415, 220]   \n",
              "29_decoder.mlp.GELU_10                            -   [128, 415, 220]   \n",
              "30_decoder.mlp.Dropout_11                         -   [128, 415, 220]   \n",
              "31_decoder.mlp.Linear_12                 [220, 220]   [128, 415, 220]   \n",
              "32_decoder.mlp.PermuteBlock_13                    -   [128, 220, 415]   \n",
              "33_decoder.mlp.BatchNorm1d_14                 [220]   [128, 220, 415]   \n",
              "34_decoder.mlp.PermuteBlock_15                    -   [128, 415, 220]   \n",
              "35_decoder.mlp.GELU_16                            -   [128, 415, 220]   \n",
              "36_decoder.mlp.Linear_17                  [220, 41]    [128, 415, 41]   \n",
              "37_decoder.LogSoftmax_softmax                     -    [128, 415, 41]   \n",
              "\n",
              "                                         Params    Mult-Adds  \n",
              "Layer                                                         \n",
              "0_encoder.embedding.PermuteBlock_0          NaN          NaN  \n",
              "1_encoder.embedding.Conv1d_1             9928.0   16379010.0  \n",
              "2_encoder.embedding.BatchNorm1d_2         146.0         73.0  \n",
              "3_encoder.embedding.GELU_3                  NaN          NaN  \n",
              "4_encoder.embedding.Dropout1d_4             NaN          NaN  \n",
              "5_encoder.embedding.Conv1d_5            24200.0   40037580.0  \n",
              "6_encoder.embedding.BatchNorm1d_6         220.0        110.0  \n",
              "7_encoder.embedding.GELU_7                  NaN          NaN  \n",
              "8_encoder.embedding.Dropout1d_8             NaN          NaN  \n",
              "9_encoder.embedding.Conv1d_9            72820.0  120661200.0  \n",
              "10_encoder.embedding.BatchNorm1d_10       440.0        220.0  \n",
              "11_encoder.embedding.GELU_11                NaN          NaN  \n",
              "12_encoder.embedding.Dropout1d_12           NaN          NaN  \n",
              "13_encoder.embedding.Conv1d_13          97020.0  160978400.0  \n",
              "14_encoder.embedding.BatchNorm1d_14       440.0        220.0  \n",
              "15_encoder.embedding.GELU_15                NaN          NaN  \n",
              "16_encoder.embedding.PermuteBlock_16        NaN          NaN  \n",
              "17_encoder.pBLSTMs.0.LSTM_blstm       2330240.0    2323200.0  \n",
              "18_encoder.pBLSTMs.1.LSTM_blstm       4269760.0    4259200.0  \n",
              "19_decoder.mlp.Linear_0                194040.0     193600.0  \n",
              "20_decoder.mlp.PermuteBlock_1               NaN          NaN  \n",
              "21_decoder.mlp.BatchNorm1d_2              880.0        440.0  \n",
              "22_decoder.mlp.PermuteBlock_3               NaN          NaN  \n",
              "23_decoder.mlp.GELU_4                       NaN          NaN  \n",
              "24_decoder.mlp.Dropout_5                    NaN          NaN  \n",
              "25_decoder.mlp.Linear_6                 97020.0      96800.0  \n",
              "26_decoder.mlp.PermuteBlock_7               NaN          NaN  \n",
              "27_decoder.mlp.BatchNorm1d_8              440.0        220.0  \n",
              "28_decoder.mlp.PermuteBlock_9               NaN          NaN  \n",
              "29_decoder.mlp.GELU_10                      NaN          NaN  \n",
              "30_decoder.mlp.Dropout_11                   NaN          NaN  \n",
              "31_decoder.mlp.Linear_12                48620.0      48400.0  \n",
              "32_decoder.mlp.PermuteBlock_13              NaN          NaN  \n",
              "33_decoder.mlp.BatchNorm1d_14             440.0        220.0  \n",
              "34_decoder.mlp.PermuteBlock_15              NaN          NaN  \n",
              "35_decoder.mlp.GELU_16                      NaN          NaN  \n",
              "36_decoder.mlp.Linear_17                 9061.0       9020.0  \n",
              "37_decoder.LogSoftmax_softmax               NaN          NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752cf176-e8c4-4448-b724-8c917cd1376e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_encoder.embedding.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 27, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_encoder.embedding.Conv1d_1</th>\n",
              "      <td>[27, 73, 5]</td>\n",
              "      <td>[128, 73, 1662]</td>\n",
              "      <td>9928.0</td>\n",
              "      <td>16379010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_encoder.embedding.BatchNorm1d_2</th>\n",
              "      <td>[73]</td>\n",
              "      <td>[128, 73, 1662]</td>\n",
              "      <td>146.0</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_encoder.embedding.GELU_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 73, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_encoder.embedding.Dropout1d_4</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 73, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_encoder.embedding.Conv1d_5</th>\n",
              "      <td>[73, 110, 3]</td>\n",
              "      <td>[128, 110, 1662]</td>\n",
              "      <td>24200.0</td>\n",
              "      <td>40037580.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_encoder.embedding.BatchNorm1d_6</th>\n",
              "      <td>[110]</td>\n",
              "      <td>[128, 110, 1662]</td>\n",
              "      <td>220.0</td>\n",
              "      <td>110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_encoder.embedding.GELU_7</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 110, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_encoder.embedding.Dropout1d_8</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 110, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_encoder.embedding.Conv1d_9</th>\n",
              "      <td>[110, 220, 3]</td>\n",
              "      <td>[128, 220, 1662]</td>\n",
              "      <td>72820.0</td>\n",
              "      <td>120661200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_encoder.embedding.BatchNorm1d_10</th>\n",
              "      <td>[220]</td>\n",
              "      <td>[128, 220, 1662]</td>\n",
              "      <td>440.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_encoder.embedding.GELU_11</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 220, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_encoder.embedding.Dropout1d_12</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 220, 1662]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_encoder.embedding.Conv1d_13</th>\n",
              "      <td>[220, 220, 2]</td>\n",
              "      <td>[128, 220, 1663]</td>\n",
              "      <td>97020.0</td>\n",
              "      <td>160978400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_encoder.embedding.BatchNorm1d_14</th>\n",
              "      <td>[220]</td>\n",
              "      <td>[128, 220, 1663]</td>\n",
              "      <td>440.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_encoder.embedding.GELU_15</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 220, 1663]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_encoder.embedding.PermuteBlock_16</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 1663, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_encoder.pBLSTMs.0.LSTM_blstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[80412, 440]</td>\n",
              "      <td>2330240.0</td>\n",
              "      <td>2323200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_encoder.pBLSTMs.1.LSTM_blstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[40177, 440]</td>\n",
              "      <td>4269760.0</td>\n",
              "      <td>4259200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_decoder.mlp.Linear_0</th>\n",
              "      <td>[440, 440]</td>\n",
              "      <td>[128, 415, 440]</td>\n",
              "      <td>194040.0</td>\n",
              "      <td>193600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_decoder.mlp.PermuteBlock_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 440, 415]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_decoder.mlp.BatchNorm1d_2</th>\n",
              "      <td>[440]</td>\n",
              "      <td>[128, 440, 415]</td>\n",
              "      <td>880.0</td>\n",
              "      <td>440.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_decoder.mlp.PermuteBlock_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 440]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_decoder.mlp.GELU_4</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 440]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_decoder.mlp.Dropout_5</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 440]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_decoder.mlp.Linear_6</th>\n",
              "      <td>[440, 220]</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>97020.0</td>\n",
              "      <td>96800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_decoder.mlp.PermuteBlock_7</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 220, 415]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_decoder.mlp.BatchNorm1d_8</th>\n",
              "      <td>[220]</td>\n",
              "      <td>[128, 220, 415]</td>\n",
              "      <td>440.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_decoder.mlp.PermuteBlock_9</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_decoder.mlp.GELU_10</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_decoder.mlp.Dropout_11</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_decoder.mlp.Linear_12</th>\n",
              "      <td>[220, 220]</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>48620.0</td>\n",
              "      <td>48400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_decoder.mlp.PermuteBlock_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 220, 415]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_decoder.mlp.BatchNorm1d_14</th>\n",
              "      <td>[220]</td>\n",
              "      <td>[128, 220, 415]</td>\n",
              "      <td>440.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_decoder.mlp.PermuteBlock_15</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_decoder.mlp.GELU_16</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 220]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_decoder.mlp.Linear_17</th>\n",
              "      <td>[220, 41]</td>\n",
              "      <td>[128, 415, 41]</td>\n",
              "      <td>9061.0</td>\n",
              "      <td>9020.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_decoder.LogSoftmax_softmax</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 415, 41]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752cf176-e8c4-4448-b724-8c917cd1376e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-752cf176-e8c4-4448-b724-8c917cd1376e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-752cf176-e8c4-4448-b724-8c917cd1376e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f37e0ae-3021-4be2-8994-73e867bb2a43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f37e0ae-3021-4be2-8994-73e867bb2a43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f37e0ae-3021-4be2-8994-73e867bb2a43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"summary(model, x\",\n  \"rows\": 38,\n  \"fields\": [\n    {\n      \"column\": \"Layer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"33_decoder.mlp.BatchNorm1d_14\",\n          \"36_decoder.mlp.Linear_17\",\n          \"4_encoder.embedding.Dropout1d_4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kernel Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1137809.453859974,\n        \"min\": 146.0,\n        \"max\": 4269760.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          48620.0,\n          194040.0,\n          9928.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mult-Adds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47015328.314559005,\n        \"min\": 73.0,\n        \"max\": 160978400.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          193600.0,\n          96800.0,\n          16379010.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model = ASRModel(\n",
        "    input_size  = 27,\n",
        "    embed_size  = config[\"embed_size\"],\n",
        "    output_size = len(PHONEMES)\n",
        ").to(device)\n",
        "print(model)\n",
        "summary(model, x.to(device), lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Config\n",
        "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\n",
        "criterion = torch.nn.CTCLoss(blank=0)# Define CTC loss as the criterion. How would the losses be reduced?\n",
        "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
        "# Refer to the handout for hints\n",
        "\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), config[\"lr\"]) # What goes in here?\n",
        "\n",
        "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
        "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "decoder = CTCBeamDecoder(\n",
        "    PHONEMES,\n",
        "    model_path=None,\n",
        "    alpha=0,\n",
        "    beta=0,\n",
        "    cutoff_top_n=40,\n",
        "    cutoff_prob=1.0,\n",
        "    beam_width=config[\"beam_width\"],\n",
        "    num_processes=4,\n",
        "    blank_id=0,\n",
        "    log_probs_input=True\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones= config[\"milestones\"], gamma= config[\"gamma\"])\n",
        "\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmc6_4eWL2Xp"
      },
      "source": [
        "# Decode Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHjnCDddL36E"
      },
      "outputs": [],
      "source": [
        "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
        "\n",
        "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
        "    # print(f\"{output.shape=}\")\n",
        "    # output = output.permute(1, 0, 2)\n",
        "    # print(f\"{output.shape=}\")\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(output, seq_lens= output_lens) #lengths - list of lengths\n",
        "\n",
        "    pred_strings = []\n",
        "\n",
        "    for i in range(output_lens.shape[0]):\n",
        "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
        "        pred_strings.append(\"\".join([PHONEME_MAP[n] for n in beam_results[i][0][:out_lens[i][0]]]))\n",
        "\n",
        "    return pred_strings\n",
        "\n",
        "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
        "\n",
        "    dist            = 0\n",
        "    batch_size      = label.shape[0]\n",
        "\n",
        "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # TODO: Get predicted string and label string for each element in the batch\n",
        "        pred_string = pred_strings[i]\n",
        "        label_string = \"\".join([PHONEME_MAP[n] for n in label[i]])\n",
        "        label_string = label_string.replace(\" \", \"\")\n",
        "\n",
        "        dist += Levenshtein.distance(pred_string, label_string)\n",
        "\n",
        "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
        "    # raise NotImplemented\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qk9iZud1LXT"
      },
      "source": [
        "# Test Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnTLL-5gMBrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61d6a61-61dc-4f84-8ebd-3c8a67ec4406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 734, 41])\n",
            "torch.Size([734, 128, 41]) torch.Size([128, 265])\n",
            "tensor(7.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Levenshtein Dist:  205.2265625\n"
          ]
        }
      ],
      "source": [
        "# test code to check shapes\n",
        "\n",
        "model.eval()\n",
        "for i, data in enumerate(val_loader, 0):\n",
        "    x, y, lx, ly = data\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    h, lh = model(x, lx)\n",
        "    print(h.shape)\n",
        "    h = torch.permute(h, (1, 0, 2))\n",
        "    print(h.shape, y.shape)\n",
        "    loss = criterion(h, y, lh, ly)\n",
        "    print(loss)\n",
        "\n",
        "    print(\"Levenshtein Dist: \", calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lx, ly, decoder, LABELS))\n",
        "    # print(\"Levenshtein Dist: \", calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd5aNaLVoR_g"
      },
      "source": [
        "# WandB\n",
        "\n",
        "You will need to fetch your api key from wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDduMaDIARE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292e3e5e-af6d-468b-d0f1-98c844b20869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"58cec1d955c8a558ddb5374428c04433fd0455c6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s52yBOvICPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1c59aa0a-ddb6-4e66-e392-119453750e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33matrela\u001b[0m (\u001b[33matrela-cmu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240329_144521-8acsznau</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/atrela-cmu/hw3p2-ablations/runs/8acsznau/workspace' target=\"_blank\">transforms-1</a></strong> to <a href='https://wandb.ai/atrela-cmu/hw3p2-ablations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/atrela-cmu/hw3p2-ablations' target=\"_blank\">https://wandb.ai/atrela-cmu/hw3p2-ablations</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/atrela-cmu/hw3p2-ablations/runs/8acsznau/workspace' target=\"_blank\">https://wandb.ai/atrela-cmu/hw3p2-ablations/runs/8acsznau/workspace</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = config['model'], ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account\n",
        "    config = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "# Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri87MAdhMUz5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16.\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    val_dist = vdist/len(val_loader)\n",
        "    return total_loss, val_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpYExu4vT4_g"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "husa5_EYMUz6"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    if metric:\n",
        "      metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExvyl1BIdMC"
      },
      "outputs": [],
      "source": [
        "# This is for checkpointing, if you're doing it over multiple sessions\n",
        "\n",
        "SAVE_DIR_ARCH = \"/content/drive/MyDrive/s24-idl/hw3p2/Alec/archs\"\n",
        "SAVE_DIR_CHECK = \"/content/drive/MyDrive/s24-idl/hw3p2/Alec/checkpoints\"\n",
        "SAVE_DIR_BEST = \"/content/drive/MyDrive/s24-idl/hw3p2/Alec/bests\"\n",
        "\n",
        "if not os.path.exists(SAVE_DIR_ARCH) or not os.path.exists(SAVE_DIR_CHECK) or not os.path.exists(SAVE_DIR_BEST):\n",
        "    raise Exception(\"One of the dirs does not exist\")\n",
        "\n",
        "### Save it in a txt file\n",
        "model_arch  = str(model)\n",
        "arch_file   = open(os.path.join(SAVE_DIR_ARCH + f\"/{config['model']}.txt\"), \"w\")\n",
        "file_write  = arch_file.write(model_arch)\n",
        "arch_file.close()\n",
        "\n",
        "last_epoch_completed = 0\n",
        "start = last_epoch_completed\n",
        "end = config[\"epochs\"]\n",
        "best_lev_dist = 5.5 # if you're restarting from some checkpoint, use what you saw there.\n",
        "epoch_model_path = os.path.join(SAVE_DIR_CHECK + f\"/{config['model']}\") #TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n",
        "best_model_path = os.path.join(SAVE_DIR_BEST + f\"/{config['model']}\") #TODO set best model path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR43E28rM9Ak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c7f215e051a436584d1fc7927590a19",
            "6cac6ccd8c4441438c389e5b3e5d8da1",
            "f13f84e12a7f4c7b8f91222dfc07bc0d",
            "cd4242b073de4538ba34aab87cb22197",
            "aecc24cb7c174cdda0efbd618e09d4bc",
            "4be69ef43b9b4f96b95788e171875a32",
            "b82d901727524e57a77c71d0e218c2ef",
            "b35a6868ddb44a6c8f25d962d232dc36"
          ]
        },
        "outputId": "9a120090-ba22-4e5b-a359-014cbde888f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 2.9592\t Learning Rate 0.0015000\n",
            "\tVal Dist 44.4525%\t Val Loss 1.9235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved epoch model\n",
            "\n",
            "Epoch: 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 1.5247\t Learning Rate 0.0015000\n",
            "\tVal Dist 22.0630%\t Val Loss 1.0010\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 1.0973\t Learning Rate 0.0015000\n",
            "\tVal Dist 16.0582%\t Val Loss 0.7317\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.9008\t Learning Rate 0.0015000\n",
            "\tVal Dist 12.4295%\t Val Loss 0.5668\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.7551\t Learning Rate 0.0015000\n",
            "\tVal Dist 11.0361%\t Val Loss 0.5119\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.6894\t Learning Rate 0.0015000\n",
            "\tVal Dist 9.9067%\t Val Loss 0.4625\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.6481\t Learning Rate 0.0015000\n",
            "\tVal Dist 9.4650%\t Val Loss 0.4439\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5865\t Learning Rate 0.0015000\n",
            "\tVal Dist 8.8809%\t Val Loss 0.4175\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5274\t Learning Rate 0.0015000\n",
            "\tVal Dist 8.4879%\t Val Loss 0.4081\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5487\t Learning Rate 0.0015000\n",
            "\tVal Dist 7.8641%\t Val Loss 0.3771\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4692\t Learning Rate 0.0015000\n",
            "\tVal Dist 7.8373%\t Val Loss 0.3772\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4631\t Learning Rate 0.0015000\n",
            "\tVal Dist 7.6357%\t Val Loss 0.3663\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4087\t Learning Rate 0.0015000\n",
            "\tVal Dist 6.9421%\t Val Loss 0.3325\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4339\t Learning Rate 0.0015000\n",
            "\tVal Dist 6.7668%\t Val Loss 0.3290\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4225\t Learning Rate 0.0015000\n",
            "\tVal Dist 6.9938%\t Val Loss 0.3380\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3363\t Learning Rate 0.0006000\n",
            "\tVal Dist 6.0085%\t Val Loss 0.2953\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3194\t Learning Rate 0.0006000\n",
            "\tVal Dist 5.9424%\t Val Loss 0.2914\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3412\t Learning Rate 0.0006000\n",
            "\tVal Dist 5.8847%\t Val Loss 0.2925\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2905\t Learning Rate 0.0006000\n",
            "\tVal Dist 5.7035%\t Val Loss 0.2866\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3102\t Learning Rate 0.0006000\n",
            "\tVal Dist 5.6952%\t Val Loss 0.2859\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2981\t Learning Rate 0.0002400\n",
            "\tVal Dist 5.5864%\t Val Loss 0.2804\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2791\t Learning Rate 0.0002400\n",
            "\tVal Dist 5.5188%\t Val Loss 0.2798\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2843\t Learning Rate 0.0002400\n",
            "\tVal Dist 5.6427%\t Val Loss 0.2844\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2686\t Learning Rate 0.0002400\n",
            "\tVal Dist 5.5008%\t Val Loss 0.2807\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2744\t Learning Rate 0.0002400\n",
            "\tVal Dist 5.5299%\t Val Loss 0.2818\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2668\t Learning Rate 0.0000960\n",
            "\tVal Dist 5.3984%\t Val Loss 0.2753\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2681\t Learning Rate 0.0000960\n",
            "\tVal Dist 5.3979%\t Val Loss 0.2768\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2903\t Learning Rate 0.0000960\n",
            "\tVal Dist 5.3910%\t Val Loss 0.2777\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2664\t Learning Rate 0.0000960\n",
            "\tVal Dist 5.4064%\t Val Loss 0.2764\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2547\t Learning Rate 0.0000960\n",
            "\tVal Dist 5.3146%\t Val Loss 0.2767\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2440\t Learning Rate 0.0000384\n",
            "\tVal Dist 5.3473%\t Val Loss 0.2754\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2599\t Learning Rate 0.0000384\n",
            "\tVal Dist 5.2992%\t Val Loss 0.2746\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2484\t Learning Rate 0.0000384\n",
            "\tVal Dist 5.3095%\t Val Loss 0.2746\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2606\t Learning Rate 0.0000384\n",
            "\tVal Dist 5.3607%\t Val Loss 0.2765\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2650\t Learning Rate 0.0000384\n",
            "\tVal Dist 5.3442%\t Val Loss 0.2755\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2372\t Learning Rate 0.0000154\n",
            "\tVal Dist 5.2711%\t Val Loss 0.2752\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2479\t Learning Rate 0.0000154\n",
            "\tVal Dist 5.3082%\t Val Loss 0.2751\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2428\t Learning Rate 0.0000154\n",
            "\tVal Dist 5.2964%\t Val Loss 0.2753\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2611\t Learning Rate 0.0000154\n",
            "\tVal Dist 5.3321%\t Val Loss 0.2758\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2551\t Learning Rate 0.0000154\n",
            "\tVal Dist 5.2509%\t Val Loss 0.2734\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2413\t Learning Rate 0.0000061\n",
            "\tVal Dist 5.2705%\t Val Loss 0.2740\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2407\t Learning Rate 0.0000061\n",
            "\tVal Dist 5.2500%\t Val Loss 0.2733\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2408\t Learning Rate 0.0000061\n",
            "\tVal Dist 5.2633%\t Val Loss 0.2731\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2495\t Learning Rate 0.0000061\n",
            "\tVal Dist 5.2823%\t Val Loss 0.2745\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2534\t Learning Rate 0.0000061\n",
            "\tVal Dist 5.3653%\t Val Loss 0.2770\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2300\t Learning Rate 0.0000025\n",
            "\tVal Dist 5.2610%\t Val Loss 0.2737\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2542\t Learning Rate 0.0000025\n",
            "\tVal Dist 5.3299%\t Val Loss 0.2771\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2464\t Learning Rate 0.0000025\n",
            "\tVal Dist 5.2767%\t Val Loss 0.2745\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2621\t Learning Rate 0.0000025\n",
            "\tVal Dist 5.2671%\t Val Loss 0.2738\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2347\t Learning Rate 0.0000025\n",
            "\tVal Dist 5.3036%\t Val Loss 0.2744\n",
            "Saved epoch model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='4696.149 MB of 4754.848 MB uploaded\\r'), FloatProgress(value=0.9876549338591076, m…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c7f215e051a436584d1fc7927590a19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>████████████▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dist</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.2347</td></tr><tr><td>valid_dist</td><td>5.30365</td></tr><tr><td>valid_loss</td><td>0.27443</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">transforms-1</strong> at: <a href='https://wandb.ai/atrela-cmu/hw3p2-ablations/runs/8acsznau/workspace' target=\"_blank\">https://wandb.ai/atrela-cmu/hw3p2-ablations/runs/8acsznau/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 58 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240329_144521-8acsznau/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "#TODO: Please complete the training loop\n",
        "\n",
        "for epoch in range(start, config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    train_loss              = train_model(model, train_loader, criterion, optimizer)\n",
        "    valid_loss, valid_dist  = validate_model(model, val_loader, decoder)\n",
        "    # scheduler.step(valid_dist)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
        "\n",
        "\n",
        "    wandb.log({\n",
        "        'train_loss': train_loss,\n",
        "        'valid_dist': valid_dist,\n",
        "        'valid_loss': valid_loss,\n",
        "        'lr'        : curr_lr\n",
        "    })\n",
        "\n",
        "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch,\n",
        "               f\"{epoch_model_path}_e{epoch}.pth\")\n",
        "    wandb.save(f\"{epoch_model_path}_e{epoch}.pth\")\n",
        "    print(\"Saved epoch model\")\n",
        "\n",
        "    if valid_dist <= best_lev_dist:\n",
        "        best_lev_dist = valid_dist\n",
        "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch,\n",
        "                   f\"{best_model_path}_e{epoch}.pth\")\n",
        "        wandb.save(f\"{best_model_path}_e{epoch}.pth\")\n",
        "        print(\"Saved best model\")\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2H4EEj-sD32"
      },
      "source": [
        "# Generate Predictions and Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2moYJhTWsOG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65294cb4-4be0-4dfb-de94-a640a413f780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [02:02<00:00,  5.85s/it]\n"
          ]
        }
      ],
      "source": [
        "#TODO: Make predictions\n",
        "\n",
        "# Follow the steps below:\n",
        "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
        "# 2. Get prediction string by decoding the results of the beam decoder\n",
        "\n",
        "TEST_BEAM_WIDTH = 125 #TODO\n",
        "\n",
        "test_decoder    = CTCBeamDecoder(\n",
        "    PHONEMES,\n",
        "    model_path=None,\n",
        "    alpha=0,\n",
        "    beta=0,\n",
        "    cutoff_top_n=40,\n",
        "    cutoff_prob=1.0,\n",
        "    beam_width=TEST_BEAM_WIDTH,\n",
        "    num_processes=4,\n",
        "    blank_id=0,\n",
        "    log_probs_input=True\n",
        ")#TODO\n",
        "\n",
        "results = []\n",
        "\n",
        "LOAD_PATH = \"/content/drive/MyDrive/s24-idl/hw3p2/Alec/bests/benchmark-more-MORE-pBLSTMs-transf_e37.pth\"\n",
        "if LOAD_PATH:\n",
        "  model, *_ = load_model(LOAD_PATH, model, metric=None)\n",
        "\n",
        "# model.eval()\n",
        "print(\"Testing\")\n",
        "for data in tqdm(test_loader):\n",
        "\n",
        "    x, lx   = data\n",
        "    x       = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h, lh = model(x, lx)\n",
        "\n",
        "    prediction_string = decode_prediction(h, lh, test_decoder)# TODO call decode_prediction\n",
        "    #TODO save the output in results array.\n",
        "    for result in prediction_string:\n",
        "      results.append(result)\n",
        "\n",
        "    del x, lx, h, lh\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d70dvu_lsMlv"
      },
      "outputs": [],
      "source": [
        "data_dir = f\"{root}/test-clean/random_submission.csv\"\n",
        "df = pd.read_csv(data_dir)\n",
        "df.label = results\n",
        "df.to_csv(f\"/content/drive/MyDrive/s24-idl/hw3p2/Alec/subs/final_{config['model']}_submission.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1sZmEIs4yIz"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions submit -c hw3p2asr-s24 -f submission.csv -m \"I made it!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTrYQhrKCH9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10 (main, Feb 16 2023, 02:49:39) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c7f215e051a436584d1fc7927590a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cac6ccd8c4441438c389e5b3e5d8da1",
              "IPY_MODEL_f13f84e12a7f4c7b8f91222dfc07bc0d"
            ],
            "layout": "IPY_MODEL_cd4242b073de4538ba34aab87cb22197"
          }
        },
        "6cac6ccd8c4441438c389e5b3e5d8da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aecc24cb7c174cdda0efbd618e09d4bc",
            "placeholder": "​",
            "style": "IPY_MODEL_4be69ef43b9b4f96b95788e171875a32",
            "value": "4754.871 MB of 4754.871 MB uploaded\r"
          }
        },
        "f13f84e12a7f4c7b8f91222dfc07bc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82d901727524e57a77c71d0e218c2ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b35a6868ddb44a6c8f25d962d232dc36",
            "value": 1
          }
        },
        "cd4242b073de4538ba34aab87cb22197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aecc24cb7c174cdda0efbd618e09d4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be69ef43b9b4f96b95788e171875a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b82d901727524e57a77c71d0e218c2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35a6868ddb44a6c8f25d962d232dc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}